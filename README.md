# Small-Language-Model

A compact, efficient Transformer-based model for creative text generation, trained on TinyStories using PyTorch.
This repository demonstrates a full minimal training pipeline — including preprocessing, training, inference, and checkpointing — suitable for research, workshops, and experimentation with small language models.

Reference link: [https://tinyurl.com/bartalab-workshop](https://tinyurl.com/slm-barta)
